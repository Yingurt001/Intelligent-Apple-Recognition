
# ğŸ Intelligent Apple Recognition System | è‹¹æœæ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ

A computer vision and deep learning-based system for identifying, classifying, and evaluating apples in orchard images.  
åŸºäºè®¡ç®—æœºè§†è§‰ä¸æ·±åº¦å­¦ä¹ çš„è‹¹æœå›¾åƒè¯†åˆ«ç³»ç»Ÿï¼Œå®ç°è‹¹æœè®¡æ•°ã€å®šä½ã€æˆç†Ÿåº¦è¯„ä¼°ä¸å“è´¨è¯†åˆ«ã€‚


<!-- Banner -->
<div align="center">
  <img src="Assets/Banner_1.png" width="100%" alt="Project Banner">
</div>

<!-- Badges -->
<div align="center">
  <img src="https://img.shields.io/github/stars/Yingurt001/Intelligent-Apple-Recognition" alt="Stars">
  <img src="https://img.shields.io/github/license/Yingurt001/Intelligent-Apple-Recognition" alt="License">
  <img src="https://img.shields.io/badge/python-3.8+-blue" alt="Python Version">
</div>


---

---

## ğŸ—‚ï¸ Project Overview | é¡¹ç›®æ¦‚è§ˆ

This project presents a full-stack image recognition system for apples, combining classical computer vision techniques and deep neural networks. The pipeline is designed to support fruit-picking robots by enabling accurate, automated analysis of apples in orchard images.


We focus on five core tasks:

- ğŸ Counting and locating apples using OpenCV and adaptive B-spline contour fitting 
- ğŸ”¥ Analyzing spatial distribution of apples with coordinate mapping and heatmaps
- ğŸ§  Classifying ripeness via a custom-built Convolutional Neural Network (CNN)
- ğŸ“Š Estimating mass based on 2D contour area and Monte Carlo simulation 
- ğŸ·ï¸ Classifying apples among other fruits using a ResNet-50 model with transfer learning

æœ¬é¡¹ç›®æ„å»ºäº†ä¸€å¥—å®Œæ•´çš„è‹¹æœå›¾åƒè¯†åˆ«ä¸åˆ†ææµç¨‹ï¼Œç»“åˆäº†ä¼ ç»Ÿå›¾åƒå¤„ç†ä¸æ·±åº¦å­¦ä¹ ç®—æ³•ï¼Œæ—¨åœ¨è¾…åŠ©é‡‡æ‘˜æœºå™¨äººå®ç°è‹¹æœçš„è‡ªåŠ¨æ£€æµ‹ä¸åˆ†ç±»è¯†åˆ«ã€‚


æˆ‘ä»¬çš„ç ”ç©¶ä»»åŠ¡åŒ…æ‹¬ï¼š

åˆ©ç”¨ OpenCV å’Œè‡ªé€‚åº” B æ ·æ¡è½®å»“æå–å®ç°è‹¹æœçš„è®¡æ•°ä¸å®šä½

å»ºç«‹åæ ‡ç³»ç»Ÿå¹¶ç»˜åˆ¶çƒ­åŠ›å›¾ä»¥åˆ†æè‹¹æœçš„ç©ºé—´å¯†åº¦åˆ†å¸ƒ

æ„å»º CNN æ¨¡å‹ï¼Œå¯¹è‹¹æœæˆç†Ÿåº¦è¿›è¡Œè‡ªåŠ¨åˆ¤åˆ«

åŸºäºå›¾åƒé¢ç§¯ä¸è’™ç‰¹å¡æ´›æ–¹æ³•ä¼°ç®—è‹¹æœè´¨é‡

åŸºäº ResNet-50 çš„è¿ç§»å­¦ä¹ æ¨¡å‹å®ç°å¤šç§æœå®åˆ†ç±»è¯†åˆ«

---


## ğŸ“¦ Installation | å®‰è£…æ–¹å¼  

```bash
git clone https://github.com/Yingurt001/Intelligent-Apple-Recognition.git
cd Intelligent-Apple-Recognition
pip install -r requirements.txt
```
---
##  Dataset Description | æ•°æ®é›†è¯´æ˜

The project uses image datasets of apples and mixed fruits provided by the 2023 APMCM Problem A.

###  Attachment 1: Apple Orchard Images
- 200 RGB images of harvest-ready apples in natural orchard environments
- Image size: 270 Ã— 180 pixels
- Apples are presented with various occlusion types: leaf, branch, fruit, and mixed occlusion
- Tasks: apple counting, positioning, maturity estimation, and mass estimation

###  Attachment 2: Labeled Fruit Images
- 20,705 labeled images of five fruit types: apple, carambola, pear, plum, tomato
- Each image has a size of 270 Ã— 180 pixels
- Used for training a fruit classifier model (e.g., ResNet50)

###  Attachment 3: Unlabeled Fruit Images
- 20,705 unlabeled fruit images with identical format to Attachment 2
- The task is to classify and identify apples among them using the trained model



é¡¹ç›®ä½¿ç”¨äº† 2023 APMCM A é¢˜æ‰€æä¾›çš„è‹¹æœå›¾åƒä¸æ··åˆæœè”¬å›¾åƒæ•°æ®é›†ï¼š

### é™„ä»¶1ï¼šæœå›­è‹¹æœå›¾åƒ
- å…± 200 å¼  RGB å›¾åƒï¼Œæ‹æ‘„äºè‡ªç„¶æœå›­ç¯å¢ƒ
- å›¾åƒå°ºå¯¸ï¼š270 Ã— 180 åƒç´ 
- è‹¹æœå­˜åœ¨å¤šç§é®æŒ¡æƒ…å†µï¼šå¶ç‰‡é®æŒ¡ã€æå¹²é®æŒ¡ã€æœå®é®æŒ¡ä¸æ··åˆé®æŒ¡
- ç”¨äºæ‰§è¡Œè‹¹æœè®¡æ•°ã€å®šä½ã€æˆç†Ÿåº¦ä¸è´¨é‡ä¼°è®¡ç­‰ä»»åŠ¡

### é™„ä»¶2ï¼šæ ‡æ³¨æ°´æœå›¾åƒ
- å…± 20705 å¼ å·²æ ‡æ³¨çš„æœè”¬å›¾åƒï¼ŒåŒ…æ‹¬è‹¹æœã€æ¨æ¡ƒã€æ¢¨ã€æå­å’Œç•ªèŒ„å…±äº”ç±»
- æ¯å¼ å›¾åƒå¤§å°ä¸º 270 Ã— 180 åƒç´ 
- ç”¨äºè®­ç»ƒæ°´æœè¯†åˆ«æ¨¡å‹ï¼Œå¦‚ ResNet50 ç½‘ç»œ

### é™„ä»¶3ï¼šæœªæ ‡æ³¨æ°´æœå›¾åƒ
- å…± 20705 å¼ ä¸é™„ä»¶2ç›¸åŒæ ¼å¼çš„æœªæ ‡æ³¨å›¾åƒ
- ç›®æ ‡ä¸ºä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¯†åˆ«å…¶ä¸­çš„è‹¹æœå›¾åƒ
âœ…

##  Implementation of Research Objectives | ç ”ç©¶ç›®æ ‡å®ç°è¿‡ç¨‹
### ğŸ Counting and locating apples
In natural orchard environments, apples in images often appear partially occluded, overlapped, or affected by uneven lighting and cluttered backgrounds. These challenges make traditional image processing methodsâ€”such as simple color thresholding or edge detectionâ€”insufficiently robust for accurate fruit counting. To address this, we designed and implemented a reliable apple counting pipeline that integrates image preprocessing, morphological operations, segmentation algorithms, and curve fitting techniques to enhance precision and consistency.

We began by converting raw images to grayscale and applying Gaussian filtering to smooth edges and suppress noise. Next, we performed adaptive thresholding to binarize the image based on local luminance, which ensures better segmentation under varying lighting conditions. To separate adjacent or touching apples, we applied morphological operations (erosion and dilation) and used the watershed algorithm based on distance transformation, which proved effective in isolating individual apple contours.

For contour fitting, we employed non-uniform B-spline curves to handle irregular fruit boundaries and produce smooth, accurate approximations. We then calculated the minimum enclosing circle for each contour to estimate the size and position of potential apples. Only those contours that satisfied geometric constraints were counted as valid detections.

Through this approach, we successfully identified a total of 1,657 apples across 200 test images. The resulting count distribution was visualized through histograms and laid a solid foundation for subsequent tasks such as spatial localization and mass estimation.


åœ¨è‡ªç„¶æœå›­ç¯å¢ƒä¸‹ï¼Œå›¾åƒä¸­çš„è‹¹æœå¸¸å¸¸å­˜åœ¨é®æŒ¡ã€é‡å ã€å…‰ç…§ä¸å‡ã€èƒŒæ™¯æ‚ä¹±ç­‰æƒ…å†µï¼Œå¯¼è‡´ä¼ ç»ŸåŸºäºé¢œè‰²æˆ–è¾¹ç¼˜æ£€æµ‹çš„å›¾åƒå¤„ç†æ–¹æ³•åœ¨è¯†åˆ«æœå®æ—¶è¡¨ç°ä¸ç¨³å®šã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡å¹¶å®ç°äº†ä¸€å¥—ç¨³å¥çš„å›¾åƒè®¡æ•°æµç¨‹ï¼Œç»“åˆäº†å›¾åƒé¢„å¤„ç†ã€å½¢æ€å­¦æ“ä½œã€åˆ†å‰²ç®—æ³•ä¸æ›²çº¿æ‹ŸåˆæŠ€æœ¯ï¼Œæå‡äº†è®¡æ•°ç²¾åº¦ä¸ç¨³å®šæ€§ã€‚

å…·ä½“è€Œè¨€ï¼Œé¦–å…ˆå¯¹åŸå§‹å›¾åƒè¿›è¡Œç°åº¦åŒ–å¤„ç†ï¼Œå¹¶ä½¿ç”¨é«˜æ–¯æ»¤æ³¢ä»¥å¹³æ»‘å›¾åƒã€å»é™¤å™ªå£°ã€‚éšåï¼Œæˆ‘ä»¬é‡‡ç”¨è‡ªé€‚åº”é˜ˆå€¼æ–¹æ³•å¯¹å›¾åƒè¿›è¡Œå±€éƒ¨äºŒå€¼åŒ–ï¼Œä½¿å…¶æ›´èƒ½é€‚åº”ä¸åŒå…‰ç…§åŒºåŸŸä¸‹çš„å›¾åƒç‰¹å¾ã€‚ä¸ºäº†è¿›ä¸€æ­¥æ¶ˆé™¤ä¼ªè¾¹ç¼˜å’Œåˆ†ç¦»ç²˜è¿æœå®ï¼Œæˆ‘ä»¬å¼•å…¥äº†è…èš€ä¸è†¨èƒ€æ“ä½œï¼Œä»¥åŠåŸºäºè·ç¦»å˜æ¢çš„åˆ†æ°´å²­ç®—æ³•ï¼Œä»è€Œæœ‰æ•ˆåˆ†å‰²å‡ºæ¯ä¸ªè‹¹æœçš„è½®å»“ã€‚

åœ¨è½®å»“æå–é˜¶æ®µï¼Œä¸ºå…‹æœè‹¹æœè¾¹ç¼˜å¤æ‚ã€å±€éƒ¨ä¸è§„åˆ™ç­‰é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†éå‡åŒ€ B æ ·æ¡æ›²çº¿å¯¹è½®å»“è¿›è¡Œå¹³æ»‘æ‹Ÿåˆï¼Œä½¿å…¶æ›´è´´è¿‘æœå®çœŸå®å½¢çŠ¶ã€‚éšåï¼Œæˆ‘ä»¬è®¡ç®—æ¯ä¸ªè½®å»“çš„æœ€å°å¤–æ¥åœ†ï¼Œå€Ÿæ­¤ä¼°ç®—æ¯ä¸ªè‹¹æœçš„ä½ç½®ä¸å°ºå¯¸ï¼Œå¹¶ä»¥æ­¤ä½œä¸ºæœ‰æ•ˆæœå®çš„ç»Ÿè®¡ä¾æ®ã€‚

é€šè¿‡è¿™ä¸€æµç¨‹ï¼Œæˆ‘ä»¬åœ¨ 200 å¼ æµ‹è¯•å›¾åƒä¸­å…±è¯†åˆ«å‡º 1657 ä¸ªè‹¹æœï¼Œæ„å»ºäº†å®Œæ•´çš„è®¡æ•°åˆ†å¸ƒå›¾ï¼Œå¹¶ä¸ºåç»­çš„ç©ºé—´å®šä½ã€è´¨é‡ä¼°è®¡ç­‰ä»»åŠ¡æ‰“ä¸‹äº†åšå®çš„åŸºç¡€ã€‚


---
## ğŸ§± Project Structure | é¡¹ç›®ç»“æ„

```bash
â”œâ”€â”€ Apple CNN/                           # CNN-based fruit classification (EffNetB0)
â”‚   â”œâ”€â”€ fruit_classifier_effnetb0.h5     # Trained classification model
â”‚   â”œâ”€â”€ Test.ipynb                       # Inference and visualization notebook
â”‚   â”œâ”€â”€ Test/                            # Test images
â”‚   â””â”€â”€ Prediction_Results/             # Output predictions with labels
â”œâ”€â”€ Assets/                              # Project illustration images
â”‚   â”œâ”€â”€ Banner_1.png
â”‚   â”œâ”€â”€ 3_comparison.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Code Attachment/                     # Code files and references for Q3/Q4
â”‚   â”œâ”€â”€ q3_process.ipynb
â”‚   â”œâ”€â”€ apple_counts.xlsx
â”‚   â”œâ”€â”€ æ ‡è®°åæ ‡.ipynb
â”‚   â”œâ”€â”€ è’™ç‰¹å¡æ´›.xlsx
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Data/                                # Official APMCM datasets
â”‚   â”œâ”€â”€ Attachment 1/                    # Orchard apple images
â”‚   â”œâ”€â”€ Attachment 2/                    # Labeled fruit dataset (5 categories)
â”‚   â”œâ”€â”€ Attachment 3/                    # Unlabeled fruit dataset
â”‚   â””â”€â”€ Archive.zip
â”œâ”€â”€ Demo/                                # One-stop notebook demo and attachments
â”‚   â”œâ”€â”€ Code_ALL.ipynb
â”‚   â”œâ”€â”€ Attachment_1/
â”‚   â”œâ”€â”€ Attachment_2/
â”‚   â””â”€â”€ Q2 Results/
â”œâ”€â”€ notebooks/                           # Q1 main analysis pipeline
â”‚   â”œâ”€â”€ 1_resnet50_fruit_classification.ipynb  # Fruit type classification (ResNet50)
â”‚   â”œâ”€â”€ 2_count_location.ipynb                  # Apple counting & localization
â”‚   â”œâ”€â”€ 3_location_scatter_heatmap.ipynb        # Spatial distribution analysis
â”‚   â”œâ”€â”€ 4_maturity_cnn.ipynb                    # Maturity classification (CNN)
â”‚   â”œâ”€â”€ 5_mass_montecarlo.ipynb                 # Mass estimation via simulation
â”‚   â”œâ”€â”€ README_Q1.md
â”‚   â””â”€â”€ results/
â”œâ”€â”€ Results/                             # Final results by task
â”‚   â”œâ”€â”€ Q1_results/
â”‚   â”œâ”€â”€ Q2 Results/
â”‚   â”œâ”€â”€ Q3 Results/
â”‚   â””â”€â”€ Q4 Results/
â”œâ”€â”€ Results_detail/                      # Augmented versions of prediction results
â”‚   â”œâ”€â”€ Attachment_2_RedBoost/
â”‚   â”œâ”€â”€ Attachment_3_Gamma/
â”‚   â”œâ”€â”€ Final_output_Sharpen/
â”‚   â”œâ”€â”€ LAB.ipynb
â”‚   â”œâ”€â”€ apple_counts_summary_v2_v2.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ environment.yml                      # Conda environment config
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md

```
<h3>Result</h3>

<p align="center">
  <img src="https://raw.githubusercontent.com/Yingurt001/Intelligent-Apple-Recognition/main/Assets/image_24.png" width="45%">
  <img src="https://raw.githubusercontent.com/Yingurt001/Intelligent-Apple-Recognition/main/Assets/image_3.png" width="45%">
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/Yingurt001/Intelligent-Apple-Recognition/main/Assets/3_comparison.jpg" width="80%">
</p>

---

### Visual Classification Results | åˆ†ç±»é¢„æµ‹å¯è§†åŒ–å±•ç¤º

We present visual examples of fruit classification using our trained model. Each prediction image shows the top-1 class label and confidence score.

ä»¥ä¸‹å±•ç¤ºæ¨¡å‹å¯¹ä¸åŒæœå®ï¼ˆè‹¹æœã€æ¢¨ã€ç•ªèŒ„ï¼‰çš„åˆ†ç±»é¢„æµ‹ç»“æœï¼Œå¯è§†åŒ–æ¨¡å‹è¯†åˆ«æ•ˆæœä¸å‡†ç¡®æ€§ã€‚

<p align="center">
  <img src="Assets/Green_apple.jpg" width="30%" title="Green Apple">
  <img src="Assets/Pear.jpg" width="30%" title="Pear">
  <img src="Assets/Tomato.jpg" width="30%" title="Tomato">
</p>

<p align="center">
  <em>Figure: Sample predictions from the classification model.</em>
</p>


 
### ğŸ‘¨â€ğŸ’» Project Maintainers
Thanks goes to these wonderful people:
<table>
  <tr>
    <td align="center">
      <a href="https://github.com/Yingurt001">
        <img src="https://avatars.githubusercontent.com/u/214812635?v=4" width="100px;" alt="Yingurt001"/>
        <br />
        <sub><b>Ying Zhang</b></sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/Alex-TtTT">
        <img src="https://avatars.githubusercontent.com/u/223631305?v=4" width="100px;" alt="Alex-TtTT"/>
        <br />
        <sub><b>Alex Hua</b></sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/Lychee-1013z">
        <img src="https://avatars.githubusercontent.com/u/221976648?v=4" width="100px;" alt="Lychee-1013z"/>
        <br />
        <sub><b>Yuzhi Zheng</b></sub>
      </a>
    </td>
  </tr>
</table>




## Contributions|è‡´è°¢

Author: Ying Zhang, Tianhao Hua, Yuzhi Zheng

GitHub: @Yingurt001, @Alex-TtTT, @Lychee-1013z

Email: millionyogurt@gmail.com,
       lychee1013z@gmail.com
       Alex.o.0@outlook.com

æ¬¢è¿ star / fork æœ¬é¡¹ç›®ï¼Œä¹Ÿæ¬¢è¿æå‡ºæ”¹è¿›å»ºè®®ä¸åˆä½œ ğŸ™Œ
